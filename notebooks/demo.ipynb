{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7634c846-5290-4a4d-8cfb-7555424d8de7",
   "metadata": {},
   "source": [
    "# Template Learning and Template Matching Pipeline Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96d3f4-c8dc-46cd-bf22-858fd0c2533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lipstick import GifMaker\n",
    "\n",
    "# For creating simulated neurons\n",
    "from laminr.simulation.neurons import neuron1_generator, neuron2_generator, neuron3_generator, complex_neuron_generator, even_gabor_neuron_generator, odd_gabor_neuron_generator, phase_invariant_neuron_generator\n",
    "from laminr.simulation.utils import random_transformation_matrices, plot_grid_points, plot_grid_border\n",
    "\n",
    "# For MEI generation\n",
    "from laminr.utils.mei import generate_mei\n",
    "\n",
    "# For template learning and template matching\n",
    "from laminr.cppn import CPPNTemplates\n",
    "from laminr.utils.pipeline import forward\n",
    "from laminr.utils.trainer_functions import train_template, match_template\n",
    "\n",
    "# For results\n",
    "from laminr.datamodule import JitteringGridDatamodule\n",
    "from laminr.utils.plot_utils import arrange_images_on_circle # plot_utils.py\n",
    "\n",
    "neuron_type_generators = {\n",
    "    \"even_gabor\": even_gabor_neuron_generator,\n",
    "    \"odd_gabor\": odd_gabor_neuron_generator,\n",
    "    \"complex_cell\": complex_neuron_generator,\n",
    "    \"arbitrary_invariance_1\": neuron1_generator,\n",
    "    \"arbitrary_invariance_2\": neuron2_generator,\n",
    "    \"arbitrary_invariance_3\": neuron3_generator,\n",
    "}\n",
    "\n",
    "random_seed = 41\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc025f-c8e6-4567-83ab-e021b17aceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_cell_model(nn.Module):\n",
    "    def __init__(self, model, idx):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.idx = idx\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)[:, self.idx].squeeze()\n",
    "\n",
    "class ArbitraryMultiNeuronModel(nn.Module):\n",
    "    def __init__(self, neuron_models_list, order=None):\n",
    "        super().__init__()\n",
    "        self.neuron_models_list = nn.ModuleList(neuron_models_list)\n",
    "        self.order = order\n",
    "        if self.order is not None:\n",
    "            if len(self.order) != len(self.neuron_models_list):\n",
    "                raise ValueError(\"order should have the same number of elements as models.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        preds = []\n",
    "        for model in self.neuron_models_list:\n",
    "            preds.append(model(x))\n",
    "        return torch.stack(preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94905468-a61c-4993-9d91-e72c3d09b595",
   "metadata": {},
   "source": [
    "## 1. Create two simulated neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f03e28-6aac-4100-9478-6081ee096699",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "img_res = [100, 100]\n",
    "\n",
    "neuron_types = [\n",
    "    \"complex_cell\",\n",
    "    \"complex_cell\"\n",
    "]\n",
    "\n",
    "num_neurons = len(neuron_types)\n",
    "global_locations = np.random.rand(num_neurons, 2) * .4 - .2\n",
    "transformation_matrices = random_transformation_matrices(num_neurons)\n",
    "transformation_matrices = np.array([np.linalg.inv(tmat) for tmat in transformation_matrices])\n",
    "\n",
    "neuron_models = []\n",
    "for neuron_type, gloc, tmat in zip(neuron_types, global_locations, transformation_matrices):\n",
    "    neuron_generator = neuron_type_generators[neuron_type]\n",
    "    print(neuron_generator)\n",
    "    neuron_model, _ = neuron_generator(gloc, img_res, transformation_matrix=tmat)\n",
    "    neuron_models.append(neuron_model)\n",
    "\n",
    "model = ArbitraryMultiNeuronModel(neuron_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f333f-703e-403f-b6d0-882ca0d1f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a018e99-5274-42f5-b410-3d5419d2b626",
   "metadata": {},
   "source": [
    "## 2. Optimize MEIs (and get the MEI activation and the RF mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193e35b-ab18-45fd-b101-22e58ec668c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.arange(len(neuron_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f03a4b-8713-4369-bae0-5ae598e44d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1\n",
    "zscore = .5\n",
    "\n",
    "# initialize dictionaries to save data in\n",
    "meis = {}\n",
    "acts = {}\n",
    "masks = {}\n",
    "center_pos = {}\n",
    "\n",
    "# generate mei data for each neurons in idxs\n",
    "for idx_n, idx in enumerate(idxs):\n",
    "    print(f'neuron_idx = {idx+1}: neuron number {idx_n+1}/{len(idxs)}')\n",
    "    \n",
    "    # single_neuron_model = neuron_models[idx].to(device)\n",
    "    single_neuron_model = single_cell_model(model, idx).to(device)\n",
    "    mei, mei_act, mask, mask_center = generate_mei(single_neuron_model, img_res, norm=norm, zscore=zscore)\n",
    "    \n",
    "    # Save data in dictionary\n",
    "    meis[idx]= mei\n",
    "    acts[idx]= mei_act\n",
    "    masks[idx]= mask\n",
    "    center_pos[idx]= mask_center\n",
    "    \n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(np.concatenate((mei, mask), axis=1), vmin=-np.abs(mei).max(), vmax=np.abs(mei).max(), cmap=\"gray\", origin=\"lower\")\n",
    "    ax.scatter(mask_center[\"x\"], mask_center[\"y\"], s=20, c=\"crimson\")\n",
    "    ax.scatter(mask_center[\"x\"]+img_res[0], mask_center[\"y\"], s=20, c=\"crimson\")\n",
    "    ax.plot(img_res, [0, img_res[1]], c=\"k\", lw=.5)\n",
    "    ax.set(xticks=[], yticks=[], xlim=(0, img_res[0] * 2-1), ylim=(0, img_res[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843f45c-b5e6-4db8-bc70-0c875dddebd7",
   "metadata": {},
   "source": [
    "## 3. Template learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17749e-15dd-4a30-b3f4-cb6428b691e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_neuron_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1849b4-1f93-4166-8b15-7f5db7613527",
   "metadata": {},
   "outputs": [],
   "source": [
    "meis = np.array([v for v in meis.values()]).astype(np.float32)\n",
    "mei_acts = np.array([v for v in acts.values()]).astype(np.float32)\n",
    "masks = np.array([v.cpu().data.numpy() for v in masks.values()]).astype(np.float32)\n",
    "rf_positions = np.array([[v[\"x\"], v[\"y\"]] for v in center_pos.values()]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09252bab-d985-49e5-aa98-7236d208c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_scale = True\n",
    "allow_shear = True\n",
    "uniform_scale = False\n",
    "\n",
    "img_res = meis[0].shape\n",
    "batch_size = 1\n",
    "template_config = dict(    \n",
    "    num_neurons=batch_size,\n",
    "    img_res=img_res,\n",
    "    num_templates=1,\n",
    "    out_channels=1,\n",
    "    widths = [50] * 4,\n",
    "    positional_encoding_dim=50,\n",
    "    positional_encoding_projection_scale=10,\n",
    "    aux_positional_encoding_dim=50,\n",
    "    aux_positional_encoding_projection_scale=.1,\n",
    "    periodic_invariance=True,\n",
    "    nonlinearity=nn.Tanh,\n",
    "    final_nonlinearity=nn.Tanh,\n",
    "    weights_scale=.1,\n",
    "    bias=True,\n",
    "    only_affine_coordinate_transformation=True,\n",
    "    stochastic_coordinate_transformation=False,\n",
    "    allow_scale_coordinate_transformation=allow_scale,\n",
    "    allow_shear_coordinate_transformation=allow_shear,\n",
    "    uniform_scale_coordinate_transformation=uniform_scale,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ab7e9-10c6-48a6-b5cb-7d95ac5a49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_min = -10 \n",
    "pixel_max = 10\n",
    "mean_pixel_val = (pixel_max + pixel_min)/2\n",
    "baseline_input = torch.ones(1, 1, *img_res) * mean_pixel_val\n",
    "baseline_input = baseline_input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3767b-a96b-438f-97c4-7d74907cd3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_neuron_model = neuron_models[template_neuron_idx].to(device)\n",
    "template_neuron_model = single_cell_model(model, template_neuron_idx).to(device)\n",
    "template_rf_location = rf_positions[template_neuron_idx]\n",
    "template_mei_act = mei_acts[template_neuron_idx]\n",
    "template_rf_mask = masks[template_neuron_idx]\n",
    "\n",
    "template = CPPNTemplates(**template_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8f3bd-7b62-4c3e-845e-28f2b12da247",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Template\")\n",
    "requirements = dict(avg=.99, std=1., necessary_min=0.98)\n",
    "grid, template, img_transforms, grid_dataloader = train_template(\n",
    "    template, \n",
    "    template_neuron_model, \n",
    "    template_rf_mask, \n",
    "    template_mei_act, \n",
    "    requirements, \n",
    "    steps_per_epoch=50, \n",
    "    pixel_min=pixel_min, \n",
    "    pixel_max=pixel_max,\n",
    "    std=None, \n",
    "    norm=1., \n",
    "    gaussian_blur_sigma=None, \n",
    "    img_transform='FixEnergyNormClip', # used with norm\n",
    "    num_max_epochs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aae12b-07a3-4115-b574-69f107c85917",
   "metadata": {},
   "source": [
    "## 4. Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6396b1-679c-4d9b-9549-58ac719d53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_neurons_idx = [1]\n",
    "others_mei_act = torch.from_numpy(mei_acts[target_neurons_idx]).to(device)\n",
    "others_rf_mask = masks[target_neurons_idx]\n",
    "others_rf_location = rf_positions[target_neurons_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e299c43-bd7c-42c1-8197-da5de0bc65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template.reset_coordinate_transform(num_neurons=len(target_neurons_idx))\n",
    "template.register_coords_shifts(torch.from_numpy(template_rf_location).to(device), torch.from_numpy(others_rf_location).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d55ac-72f5-45ca-bfb1-38789ec4dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = match_template(\n",
    "    template, \n",
    "    model, \n",
    "    img_transforms, \n",
    "    grid_dataloader, \n",
    "    template_rf_mask, \n",
    "    np.arange(len(target_neurons_idx)),\n",
    "    target_neurons_idx, \n",
    "    others_mei_act, \n",
    "    others_rf_mask, \n",
    "    rotate_angle_and_scale=True,\n",
    "    patience=25,\n",
    "    num_epochs=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962cb839-a835-4bae-9762-6abba2ea6e85",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ee52a-203c-44bf-8963-4a91b14621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_config = dict(\n",
    "    num_invariances=1,\n",
    "    grid_points_per_dim=24,\n",
    "    steps_per_epoch=1,\n",
    ")\n",
    "grid_dataloader = JitteringGridDatamodule(**dataloader_config)\n",
    "grid = grid_dataloader.grid.clone().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7f1dc-7b9f-4ddc-b908-90c015f63cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    template_act_baseline = template_neuron_model(baseline_input).item()\n",
    "\n",
    "    # invariance activation\n",
    "    template_img_pre, template_img_post, template_acts, _ = forward(grid, template, img_transforms, template_neuron_model, return_template=True)\n",
    "    template_act = template_acts.mean().item()\n",
    "    template_act_relative = (template_act - template_act_baseline)/(template_mei_act - template_act_baseline)\n",
    "\n",
    "    others_img_pre, others_img_post, others_acts, _ = forward(grid, template, img_transforms, model, return_template=False, \n",
    "                                                              other_neurons_loc_in_list=np.arange(len(target_neurons_idx)),\n",
    "                                                              other_neurons_loc_in_model=target_neurons_idx)\n",
    "    others_act = others_acts.mean(dim=1).diag().cpu().data.numpy()\n",
    "    others_act_baseline = model(baseline_input)[0, target_neurons_idx].cpu().data.numpy()\n",
    "    others_act_relative = (others_act - others_act_baseline) / (mei_acts[target_neurons_idx] - others_act_baseline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99912de5-7c19-4327-8759-4fd2ab5b701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_manifold = template_img_post.cpu().data.numpy()\n",
    "matched_manifold = others_img_post[0].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea843c8-2b9d-4b3a-8a68-2ae256cb723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = max(np.abs(template_manifold).max(), np.abs(matched_manifold).max())\n",
    "min_val = -max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538c71a-b64b-407b-a0ac-334da0a5e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(template_manifold)\n",
    "\n",
    "with GifMaker(\"result.gif\") as g:\n",
    "    for img_idx in range(num_images):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        img_template_manifold = template_manifold[img_idx, 0]\n",
    "        img_matched_manifold = matched_manifold[img_idx, 0]\n",
    "        ax1.imshow(img_template_manifold, vmin=-np.abs(img_template_manifold).max(), vmax=np.abs(img_template_manifold).max(), origin=\"lower\", cmap=\"Greys_r\")\n",
    "        ax2.imshow(img_matched_manifold, vmin=-np.abs(img_matched_manifold).max(), vmax=np.abs(img_matched_manifold).max(), origin=\"lower\", cmap=\"Greys_r\")\n",
    "        ax1.set(xticks=[], yticks=[])\n",
    "        ax2.set(xticks=[], yticks=[])\n",
    "        g.add(fig)\n",
    "g.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818658a-e3a0-43c1-b235-ed4fe9842d8a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
